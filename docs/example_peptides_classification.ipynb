{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Peptides classification with subsequence string kernel\n",
    "\n",
    "This notebook details the utilization of Scikit-Learn to search for the best Support Vector Machine (SVM) model for the classification of peptides sequences using the subsequence string kernel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Dataset preparation\n",
    "\n",
    "This example is about antimicrobial peptides classification. We used the data and experimental methodology of the research conducted by P. Bhadra and collaborators.\n",
    "\n",
    "The data consists of a dataset with a 1:3 positive to negative ratio, AMP/non-AMP peptide sequences. The dataset containing AMP and non-AMP data is freely available at https://sourceforge.net/projects/axpep/files/. \n",
    "\n",
    "The original work employs a 10-fold cross-validation for training a Random Forest model and obtains an MCC score of 0.90.\n",
    "\n",
    "**Reference**: P. Bhadra, J. Yan, J. Li, S. Fong, and S. W. Siu. AmPEP: Sequence-based prediction of antimicrobial peptides using distribution patterns of amino acid properties and random forest. Scientific Reports, vol. 8, no. 1, pp. 1â€“10, 2018."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading required packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sys import path as sys_path\n",
    "sys_path.append('..')\n",
    "\n",
    "from os import path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import (make_scorer, \n",
    "                             matthews_corrcoef,\n",
    "                             accuracy_score,\n",
    "                             recall_score,\n",
    "                             confusion_matrix,\n",
    "                             roc_auc_score)\n",
    "\n",
    "from strkernels import SubsequenceStringKernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step involves loading the dataset and creating a dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining a function to create a dataframe from a FASTA file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_fasta_to_dataframe(fasta_file):\n",
    "    data = []\n",
    "    with open(fasta_file, 'r') as file:\n",
    "        sequence_id = None\n",
    "        sequence = []\n",
    "        \n",
    "        for line in file:\n",
    "            line = line.strip()\n",
    "            if line.startswith('>'):\n",
    "                if sequence_id is not None:\n",
    "                    data.append([sequence_id, ''.join(sequence)])\n",
    "                sequence_id = line[1:]\n",
    "                sequence = []\n",
    "            else:\n",
    "                sequence.append(line)\n",
    "        \n",
    "        if sequence_id is not None:\n",
    "            data.append([sequence_id, ''.join(sequence)])\n",
    "    \n",
    "    df = pd.DataFrame(data, columns=['seqid', 'sequence'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the positive sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "amp_seqs_file_path = path.join('data', 'Bhadra-et-al-2018', 'train_AMP_3268.fasta')\n",
    "amp_df = read_fasta_to_dataframe(amp_seqs_file_path)\n",
    "amp_df['label'] = 1\n",
    "amp_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the negative sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_amp_seqs_file_path = path.join('data', 'Bhadra-et-al-2018', 'train_nonAMP_9777.fasta')\n",
    "non_amp_df = read_fasta_to_dataframe(non_amp_seqs_file_path)\n",
    "non_amp_df['label'] = -1\n",
    "non_amp_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a single dataframe with the positive and negative sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.concat([amp_df, non_amp_df])\n",
    "data_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separating 25% of the sequences for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 1708  # for reproducing\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_df['sequence'], \n",
    "                                                    data_df['label'], \n",
    "                                                    stratify=data_df['label'], \n",
    "                                                    random_state=random_seed)\n",
    "print('Number of train sequences:',len(X_train))\n",
    "print('Number of test sequences:',len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Hyperparameters selection\n",
    "\n",
    "Now, we will search for the best value for the hyperparameters maximum subsequence length and decay of the subsequence string kernel and C hyperparameter of SVM for this dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For better performance, we will only use 10% of the train samples in hyperparameters selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.concat([X_train, y_train], axis=1)\n",
    "pos_train_df = train_df[train_df['label'] == 1]\n",
    "neg_train_df = train_df[train_df['label'] == -1]\n",
    "\n",
    "sampled_pos_train_df = pos_train_df.sample(n=len(pos_train_df) // 5, random_state=random_seed)\n",
    "sampled_pos_train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_balanced_neg_train_df = neg_train_df.sample(n=len(sampled_pos_train_df), random_state=random_seed)\n",
    "sampled_balanced_neg_train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_train_df = pd.concat([sampled_pos_train_df, sampled_balanced_neg_train_df])\n",
    "sampled_train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating the subsequence string kernel instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "subsequence_kernel = SubsequenceStringKernel(maxlen=1, ssk_lambda=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a support vector classifier with the kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SVC(kernel=subsequence_kernel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running grid search with 10-fold cross-validation for searching the better subsequence string kernel hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set parameters for grid search\n",
    "param_grid = {\n",
    "    'kernel__maxlen': [4, 5, 6],\n",
    "    'kernel__ssk_lambda': [0.9, 1.0, 1.1, 1.2, 1.3],\n",
    "}\n",
    "\n",
    "# create the evaluation metric\n",
    "mcc_scorer = make_scorer(matthews_corrcoef)\n",
    "\n",
    "# create the GridSearchCV object\n",
    "grid_search = GridSearchCV(estimator=clf, \n",
    "                           param_grid=param_grid, \n",
    "                           scoring=mcc_scorer, \n",
    "                           cv=10,\n",
    "                           n_jobs=-1, \n",
    "                           verbose=3)\n",
    "\n",
    "# fit the model to the training data\n",
    "grid_search.fit(sampled_train_df['sequence'], sampled_train_df['label'])\n",
    "\n",
    "# show the best parameters\n",
    "best_params = grid_search.best_params_\n",
    "print(\"\\nBest parameters:\", best_params)\n",
    "\n",
    "# show the best mean validation score\n",
    "best_score = grid_search.best_score_\n",
    "print(f\"Best mean validation score: {best_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Searching a better C hyperparameter of SVM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set parameters for grid search\n",
    "param_grid = {\n",
    "    'kernel__maxlen': [5],\n",
    "    'kernel__ssk_lambda': [1.1],\n",
    "    'C': [0.1, 1.0, 10.0]\n",
    "}\n",
    "\n",
    "# create the evaluation metric\n",
    "mcc_scorer = make_scorer(matthews_corrcoef)\n",
    "\n",
    "# create the GridSearchCV object\n",
    "grid_search = GridSearchCV(estimator=clf, \n",
    "                           param_grid=param_grid, \n",
    "                           scoring=mcc_scorer, \n",
    "                           cv=10,\n",
    "                           n_jobs=-1, \n",
    "                           verbose=3)\n",
    "\n",
    "# fit the model to the training data\n",
    "grid_search.fit(sampled_train_df['sequence'], sampled_train_df['label'])\n",
    "\n",
    "# show the best parameters\n",
    "best_params = grid_search.best_params_\n",
    "print(\"\\nBest parameters:\", best_params)\n",
    "\n",
    "# show the best mean validation score\n",
    "best_score = grid_search.best_score_\n",
    "print(f\"Best mean validation score: {best_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Best model evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training an SVM model with the best hyperparameters found, using the full training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the kernel\n",
    "subsequence_kernel = SubsequenceStringKernel(maxlen=5, ssk_lambda=1.1)\n",
    "\n",
    "# create a support vector classifier with the kernel\n",
    "clf = SVC(C=1.0, kernel=subsequence_kernel)\n",
    "\n",
    "# train the classifier\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performing the classification on the test dataset and obtaining the scores calculated by the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_scores = clf.decision_function(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining sequence labels from scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_labels = np.where(pred_scores > 0, 1, -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating and showing evaluation metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MCC = round(matthews_corrcoef(y_test, pred_labels), 4)\n",
    "accuracy = round(accuracy_score(y_test, pred_labels)*100, 2)\n",
    "sensitivity = round(recall_score(y_test, pred_labels)*100, 2)\n",
    "TN, FP, FN, TP = confusion_matrix(y_test, pred_labels).ravel()\n",
    "specificity = round(TN / (TN + FP)*100, 2)\n",
    "AUROC = round(roc_auc_score(y_test, pred_scores), 4)\n",
    "\n",
    "print(\"MCC:\", MCC)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Sensitivity:\", sensitivity)\n",
    "print(\"Specificity:\", specificity)\n",
    "print(\"AUROC:\", AUROC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that the best SVM model achieved an MCC equal to the original tool, indicating good performance for the proposed problem."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "vscode": {
   "interpreter": {
    "hash": "c0bcc559ef33487cab7f2a2558a52d71f1a0ee6852f4c5d070acd011fceb9d44"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
